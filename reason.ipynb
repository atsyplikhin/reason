{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import yaml\n",
    "import os\n",
    "import openai\n",
    "from src.tree_node import TreeNode\n",
    "from src.api_completion import Completion\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"config.yaml\"\n",
    "\n",
    "# Load experiment config\n",
    "with open(config_file) as file:\n",
    "    cfg = yaml.load(file, Loader=yaml.loader.SafeLoader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv()\n",
    "oai_client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "generator = Completion(oai_client=oai_client)\n",
    "generator_args = {\n",
    "    \"model\": cfg[\"generator\"][\"model\"],\n",
    "    \"system\": cfg[\"generator\"][\"system_prompt\"],\n",
    "    \"max_tokens\": cfg[\"generator\"][\"max_tokens\"],\n",
    "    \"temperature\": cfg[\"generator\"][\"temperature\"],\n",
    "    \"n\": cfg[\"generator\"][\"n\"]\n",
    "}\n",
    "\n",
    "verifier = Completion(oai_client=oai_client)\n",
    "verifier_args = {\n",
    "    \"model\": cfg[\"verifier\"][\"model\"],\n",
    "    \"system\": cfg[\"verifier\"][\"system_prompt\"],\n",
    "    \"max_tokens\": cfg[\"verifier\"][\"max_tokens\"],\n",
    "    \"temperature\": cfg[\"verifier\"][\"temperature\"],\n",
    "    \"logprobs\": cfg[\"verifier\"][\"logprobs\"],\n",
    "    \"top_logprobs\": cfg[\"verifier\"][\"top_logprobs\"]\n",
    "}\n",
    "\n",
    "evaluator = Completion(oai_client=oai_client)\n",
    "evaluator_args = {\n",
    "    \"model\": cfg[\"evaluator\"][\"model\"],\n",
    "    \"system\": cfg[\"evaluator\"][\"system_prompt\"],\n",
    "    \"max_tokens\": cfg[\"evaluator\"][\"max_tokens\"],\n",
    "    \"temperature\": cfg[\"evaluator\"][\"temperature\"],\n",
    "    \"logprobs\": cfg[\"evaluator\"][\"logprobs\"],\n",
    "    \"top_logprobs\": cfg[\"evaluator\"][\"top_logprobs\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"Kacey is picking out jewelry to wear for school. She has 10 rings, 4 bracelets, and 4 necklaces. How many jewelry combinations are possible if she is going to wear 1 ring, 1 bracelet, and 2 necklaces?\"\n",
    "tree_root = TreeNode(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought 1:\n",
      "To find the number of jewelry combinations Kacey can wear, I need to multiply the number of choices for each type of jewelry.\n",
      "\n",
      "Thought 2:\n",
      "To find the total number of jewelry combinations, I need to multiply the number of choices for each type of jewelry: 10 rings, 4 bracelets, and the number of ways to choose 2 necklaces from 4.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"<task>{task}</task>\\n(no previous thoughts)\\nNext thought:\"\n",
    "result = generator.run(prompt, **generator_args)\n",
    "\n",
    "for i, choice in enumerate(result.choices):\n",
    "    print(f\"Thought {i+1}:\\n{choice.message.content}\\n\")\n",
    "    \n",
    "for choice in result.choices:\n",
    "    tree_node = TreeNode(choice.message.content)\n",
    "    tree_root.add_child(tree_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<task>Kacey is picking out jewelry to wear for school. She has 10 rings, 4 bracelets, and 4 necklaces. How many jewelry combinations are possible if she is going to wear 1 ring, 1 bracelet, and 2 necklaces?</task>\n",
      "\n",
      "Last thought:\n",
      "To find the number of jewelry combinations Kacey can wear, I need to multiply the number of choices for each type of jewelry.\n",
      "correctness_scores = {'1': 99.14, '0': 0.86}\n",
      "helpfulness_scores = {'9': 67.52, '8': 31.89, '7': 0.58, '6': 0.01, '5': 0.0, '4': 0.0, '3': 0.0, '10': 0.0, '2': 0.0, 'The': 0.0}\n",
      "\n",
      "\n",
      "<task>Kacey is picking out jewelry to wear for school. She has 10 rings, 4 bracelets, and 4 necklaces. How many jewelry combinations are possible if she is going to wear 1 ring, 1 bracelet, and 2 necklaces?</task>\n",
      "\n",
      "Last thought:\n",
      "To find the total number of jewelry combinations, I need to multiply the number of choices for each type of jewelry: 10 rings, 4 bracelets, and the number of ways to choose 2 necklaces from 4.\n",
      "correctness_scores = {'1': 99.99, '0': 0.01}\n",
      "helpfulness_scores = {'9': 72.82, '8': 26.79, '7': 0.38, '6': 0.0, '5': 0.0, '10': 0.0, 'The': 0.0, 'This': 0.0, '4': 0.0, 'I': 0.0}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "current_paths = tree_root.get_paths()\n",
    "\n",
    "for path in current_paths:\n",
    "    prompt = f\"<task>{path[0].value}</task>\\n\"\n",
    "    if len(path) > 2:\n",
    "        prompt += \"\\n\".join([node.value for node in path[1:-1]])\n",
    "    prompt += f\"\\nLast thought:\\n{path[-1].value}\"\n",
    "    verifier_result = verifier.run(prompt, **verifier_args)\n",
    "    evaluator_result = evaluator.run(prompt, **evaluator_args)\n",
    "\n",
    "    correctness_scores = {\n",
    "        logprob.token: float(np.round(np.exp(logprob.logprob)*100,2))\n",
    "        for logprob in verifier_result.choices[0].logprobs.content[0].top_logprobs    \n",
    "    }\n",
    "    helpfulness_scores = {\n",
    "        logprob.token: float(np.round(np.exp(logprob.logprob)*100,2))\n",
    "        for logprob in evaluator_result.choices[0].logprobs.content[0].top_logprobs    \n",
    "    }\n",
    "    # Update the last tree node in the path with the scores\n",
    "    path[-1].correctness_scores = correctness_scores\n",
    "    path[-1].helpfulness_scores = helpfulness_scores\n",
    "    print(f\"{prompt}\\n{correctness_scores = }\\n{helpfulness_scores = }\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
